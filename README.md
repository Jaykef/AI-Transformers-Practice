# Transformers-Practice
我在变形金刚（GPTs）的实践学习经验

   
<img src='gpt.png' />

## 学习路线图
<a href="https://github.com/Jaykef/GPT-Practice/tree/main/GPT-Basic" >1. GPT基础 - 定义、代码实现、用户指南</a>

<a href="https://github.com/Jaykef/GPT-Practice/tree/main/GPT-Advance" >2. GPT高级概述、研究论文、应用 </a>

<a href="https://github.com/Jaykef/GPT-Practice/edit/main/README.md#:~:text=GPT%2D-,Basic,-GPT%2DIntermediate" >3. Huggingface Transformer - 提供Api和工具，可轻松下载和训练最先进的预训练模型 </a>

<a href="https://github.com/Jaykef/GPT-Practice/edit/main/README.md#:~:text=GPT%2D-,Basic,-GPT%2DIntermediate" >4. GPT应用程序-gpt的现实生活应用程序(例如ChatGPT,Jarvis)</a>


## 参考资料
1. 阅读资料
   <ul>
      <li><a href="https://arxiv.org/pdf/1706.03762.pdf"> Attension is All You Need 研究论文 - Google</a> </li>
      <li><a href="https://jalammar.github.io/illustrated-transformer/"> 插图Transformer - by Jay Alammar </a> </li>
      <li><a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">注释Transformer - Harvard NLP</li>
      <li><a href="https://openai.com/research/techniques-for-training-large-neural-networks"> 训练大型神经网络的技术  - Open AI</li>
      <li><a href="https://karpathy.ai/stateofgpt.pdf"> GPT的状态 - Andrej Karpathy</li>
      <li><a href="https://arxiv.org/pdf/1607.06450.pdf"> 层规范化 - Google</li> 
      <li><a href="https://en.wikipedia.org/wiki/Matrix_multiplication"> 矩阵乘法 - Wikepedia</li> 
   </ul>
   
   
3. Repos
   <ul>
      <li><a href="https://jalammar.github.io/illustrated-transformer/"> nonoGPT </a> - by Andrej Karpathy
      <li><a href="https://github.com/tensorflow/tensor2tensor">Tensor2Tensor - transformer的Tensorflow实现</li>
   </ul>
