# Transformers-Practice
My hands-on learning experience with transformers (GPTs) - <a href="https://github.com/Jaykef/GPT-Practice/blob/main/Chinese.md">中文 Readme</a>

![Image 2024-4-17 at 21 10 3](https://github.com/Jaykef/GPT-Practice/assets/11355002/8a939cf4-c1ec-41d0-87a0-167968a3042c)


## Learning Roadmap

   <ul>
      <li><a href="https://github.com/Jaykef/GPT-Practice/tree/main/GPT-Basic" >GPT Basics - definition, code implementation, use guide</a></li>
      <li><a href="https://github.com/Jaykef/GPT-Practice/tree/main/GPT-Advance" >GPT Advance - high level overview, research papers, applications </a></li>
      <li><a href="https://github.com/Jaykef/GPT-Practice/tree/main/The-Annotated-Transformer" >The Anotated Transformer - Havard </a></li>
      <li><a href="https://github.com/Jaykef/GPT-Practice/edit/main/README.md#:~:text=GPT%2D-,Basic,-GPT%2DIntermediate" >Huggingface Transformer - provides APIs and tools to easily download and train state-of-the-art pretrained models </a></li>
      <li><a href="https://github.com/Jaykef/GPT-Practice/edit/main/README.md#:~:text=GPT%2D-,Basic,-GPT%2DIntermediate" >GPT Apps - real life applications of GPT (e.g ChatGPT, Jarvis) </a></li>
</ul>

## References
Readings
   <ul>
      <li><a href="https://arxiv.org/pdf/1706.03762.pdf"> Attension is All You Need Paper - Google</a> </li>
      <li><a href="https://jalammar.github.io/illustrated-transformer/"> The Illustrated Transformer - by Jay Alammar </a> </li>
      <li><a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer - Harvard NLP</li>
      <li><a href="https://openai.com/research/techniques-for-training-large-neural-networks"> Techniques for training large neural networks - Open AI</li>
      <li><a href="https://huggingface.co/docs/transformers/">Huggingface Transformer</a></li>
      <li><a href="https://karpathy.ai/stateofgpt.pdf"> The State of GPT - Andrej Karpathy</li>
      <li><a href="https://cs231n.github.io/">CS231n Convolutional Neural Networks for Visual Recognition - Stanford</a></li>
      <li><a href="http://introtodeeplearning.com/">Intro to Deep Learning - MIT</a></li>
      <li><a href="https://arxiv.org/pdf/1607.06450.pdf"> Layer Normalization - Google</li> 
      <li><a href="https://huggingface.co/learn/nlp-course/chapter1/1">Intro To Natural Language Processing - Transformers </a></li>
      <li><a href="https://en.wikipedia.org/wiki/Matrix_multiplication"> Matrix multiplication - Wikepedia</li> 
   </ul>
   
   
Repos
   <ul>
      <li><a href="https://jalammar.github.io/illustrated-transformer/"> nanoGPT </a> - by Andrej Karpathy
      <li><a href="https://github.com/harvardnlp/annotated-transformer">The Annotated Transformer</a> - Harvard</a></li>
      <li><a href="https://github.com/tensorflow/tensor2tensor">Tensor2Tensor - Tensorflow implementation of the transformer</li>
   </ul>

## License
MIT License
